{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашее задание3. Получить выше 0.92 на TEST FASHION MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Владимир Никифоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten()\n",
      "  (1): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "ep: 0, train_loss: 0.47595429369743836, train_acc: 0.8388333333333333, test_loss: 0.3866492725908756, test_acc: 0.8616\n",
      "ep: 1, train_loss: 0.32928891321446035, train_acc: 0.8793, test_loss: 0.34114719498902557, test_acc: 0.8735\n",
      "ep: 2, train_loss: 0.2878545328657678, train_acc: 0.8941, test_loss: 0.35951814278960226, test_acc: 0.8769\n",
      "ep: 3, train_loss: 0.25812704303163164, train_acc: 0.90455, test_loss: 0.32843204848468305, test_acc: 0.8815\n",
      "ep: 4, train_loss: 0.23568312677931277, train_acc: 0.91165, test_loss: 0.3389575880020857, test_acc: 0.8805\n",
      "ep: 5, train_loss: 0.22140896593002563, train_acc: 0.9171833333333334, test_loss: 0.3220423936843872, test_acc: 0.8852\n",
      "ep: 6, train_loss: 0.20663493155164922, train_acc: 0.9215166666666667, test_loss: 0.3243516024202108, test_acc: 0.885\n",
      "ep: 7, train_loss: 0.19094893035102398, train_acc: 0.9281, test_loss: 0.33289343416690825, test_acc: 0.8855\n",
      "ep: 8, train_loss: 0.17933050964740996, train_acc: 0.9328333333333333, test_loss: 0.3212840100750327, test_acc: 0.8891\n",
      "ep: 9, train_loss: 0.16678721403821986, train_acc: 0.9376166666666667, test_loss: 0.32741873934864996, test_acc: 0.8886\n",
      "ep: 10, train_loss: 0.15603648934592593, train_acc: 0.9405833333333333, test_loss: 0.3419435787945986, test_acc: 0.8891\n",
      "ep: 11, train_loss: 0.1452578934424735, train_acc: 0.94615, test_loss: 0.3425229012966156, test_acc: 0.8912\n",
      "ep: 12, train_loss: 0.13628819439005344, train_acc: 0.9492666666666667, test_loss: 0.3626141220331192, test_acc: 0.8881\n",
      "ep: 13, train_loss: 0.12616941928863526, train_acc: 0.9535, test_loss: 0.3684361450374126, test_acc: 0.8916\n",
      "ep: 14, train_loss: 0.12019082469509003, train_acc: 0.9552666666666667, test_loss: 0.37674752026796343, test_acc: 0.89\n",
      "ep: 15, train_loss: 0.11021003116001474, train_acc: 0.9597666666666667, test_loss: 0.38821638450026513, test_acc: 0.8891\n",
      "ep: 16, train_loss: 0.10611365454945158, train_acc: 0.9602833333333334, test_loss: 0.43078010268509387, test_acc: 0.884\n",
      "ep: 17, train_loss: 0.10049765519005187, train_acc: 0.9626, test_loss: 0.4086843341588974, test_acc: 0.8888\n",
      "ep: 18, train_loss: 0.09534091727530702, train_acc: 0.96405, test_loss: 0.40331522598862646, test_acc: 0.8868\n",
      "ep: 19, train_loss: 0.08893329529686177, train_acc: 0.9671, test_loss: 0.40955171212553976, test_acc: 0.888\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    #torch.nn.Dropout(p=0.15),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.BatchNorm1d(784),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    #torch.nn.Dropout(p=0.3),\n",
    "    torch.nn.BatchNorm1d(64),\n",
    "    torch.nn.Linear(64, 10)\n",
    ")\n",
    "print(model)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    train_iters, train_passed  = 0, 0\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    \n",
    "    for X, y in train:\n",
    "        trainer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        train_loss += l.item()\n",
    "        train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        train_iters += 1\n",
    "        train_passed += len(X)\n",
    "    \n",
    "    test_iters, test_passed  = 0, 0\n",
    "    test_loss, test_acc = 0., 0.\n",
    "    for X, y in test:\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        test_loss += l.item()\n",
    "        test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        test_iters += 1\n",
    "        test_passed += len(X)\n",
    "        \n",
    "    print(\"ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "        ep, train_loss / train_iters, train_acc / train_passed,\n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже на 11 эпохе достигнуто значение 0.8912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 0.07116884039120472, train_acc: 0.9745333333333334, test_loss: 0.3879988767206669, test_acc: 0.8957\n",
      "ep: 1, train_loss: 0.0591926505273961, train_acc: 0.98025, test_loss: 0.39003591164946555, test_acc: 0.8946\n",
      "ep: 2, train_loss: 0.0555309598829518, train_acc: 0.9820833333333333, test_loss: 0.3981344260275364, test_acc: 0.8954\n",
      "ep: 3, train_loss: 0.05322467549208631, train_acc: 0.9825833333333334, test_loss: 0.39778875187039375, test_acc: 0.894\n",
      "ep: 4, train_loss: 0.05143077236382251, train_acc: 0.9838, test_loss: 0.3915284566581249, test_acc: 0.8949\n",
      "ep: 5, train_loss: 0.04893952117479862, train_acc: 0.98485, test_loss: 0.4073649846017361, test_acc: 0.8965\n",
      "ep: 6, train_loss: 0.04812022005306914, train_acc: 0.9852666666666666, test_loss: 0.42445593886077404, test_acc: 0.8966\n",
      "ep: 7, train_loss: 0.046474754081127494, train_acc: 0.9859333333333333, test_loss: 0.38879416743293405, test_acc: 0.8958\n",
      "ep: 8, train_loss: 0.04576429064445039, train_acc: 0.9860833333333333, test_loss: 0.42344827130436896, test_acc: 0.8969\n",
      "ep: 9, train_loss: 0.04517621690447026, train_acc: 0.98625, test_loss: 0.39546974673867225, test_acc: 0.8969\n",
      "ep: 10, train_loss: 0.04370550200184609, train_acc: 0.9873, test_loss: 0.4094645731151104, test_acc: 0.8962\n",
      "ep: 11, train_loss: 0.04376206959974258, train_acc: 0.9869833333333333, test_loss: 0.3909021018072963, test_acc: 0.8959\n",
      "ep: 12, train_loss: 0.04260683685065584, train_acc: 0.9869, test_loss: 0.4123356480151415, test_acc: 0.8967\n",
      "ep: 13, train_loss: 0.042602297544796414, train_acc: 0.9874666666666667, test_loss: 0.4107929177582264, test_acc: 0.8966\n",
      "ep: 14, train_loss: 0.0413203612564409, train_acc: 0.9877333333333334, test_loss: 0.39274069517850874, test_acc: 0.8973\n",
      "ep: 15, train_loss: 0.04135612340921417, train_acc: 0.9876666666666667, test_loss: 0.4094501044601202, test_acc: 0.8966\n",
      "ep: 16, train_loss: 0.04039489657003829, train_acc: 0.9878333333333333, test_loss: 0.4035427153110504, test_acc: 0.896\n",
      "ep: 17, train_loss: 0.03955909062097682, train_acc: 0.9882666666666666, test_loss: 0.4063965087756515, test_acc: 0.8956\n",
      "ep: 18, train_loss: 0.03932698290160996, train_acc: 0.9883166666666666, test_loss: 0.39861523546278477, test_acc: 0.8955\n",
      "ep: 19, train_loss: 0.03875157607204102, train_acc: 0.9887, test_loss: 0.40905448943376543, test_acc: 0.8968\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    train_iters, train_passed  = 0, 0\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    \n",
    "    for X, y in train:\n",
    "        trainer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        train_loss += l.item()\n",
    "        train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        train_iters += 1\n",
    "        train_passed += len(X)\n",
    "    \n",
    "    test_iters, test_passed  = 0, 0\n",
    "    test_loss, test_acc = 0., 0.\n",
    "    for X, y in test:\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        test_loss += l.item()\n",
    "        test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        test_iters += 1\n",
    "        test_passed += len(X)\n",
    "        \n",
    "    print(\"ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "        ep, train_loss / train_iters, train_acc / train_passed,\n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Меняя оптимизатор получилось достичь линейными слоями 0.8973, хотя получалось и 0.9 таким же запуском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка сделать автоматический поиск сходимости через движение \"тройками\" с изменением оптимизатора и learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten()\n",
      "  (1): BatchNorm1d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 0, train_loss: 0.48130598594533636, train_acc: 0.8396833333333333, test_loss: 0.41862264573574065, test_acc: 0.8486\n",
      "[0, 0, 0] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 1, train_loss: 0.32976347658228367, train_acc: 0.8795333333333333, test_loss: 0.35607807636260985, test_acc: 0.8709\n",
      "[0, 0, 0.8486] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 2, train_loss: 0.2894921096081429, train_acc: 0.89345, test_loss: 0.3430909626185894, test_acc: 0.8764\n",
      "[0, 0.8486, 0.8709] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 3, train_loss: 0.2612436349087573, train_acc: 0.9041333333333333, test_loss: 0.3466242216527462, test_acc: 0.8757\n",
      "[0.8486, 0.8709, 0.8764] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 4, train_loss: 0.23995267323991085, train_acc: 0.9112, test_loss: 0.3332759540528059, test_acc: 0.8796\n",
      "[0.8709, 0.8764, 0.8757] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 5, train_loss: 0.22298227459826367, train_acc: 0.9163333333333333, test_loss: 0.3251030813902617, test_acc: 0.8852\n",
      "[0.8764, 0.8757, 0.8796] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 6, train_loss: 0.2047792615408593, train_acc: 0.92345, test_loss: 0.3254078008234501, test_acc: 0.8812\n",
      "[0.8757, 0.8796, 0.8852] 0\n",
      "trainer_name: adam, glob_circle: 0, lr: 0.001, ep: 7, train_loss: 0.19082407697718196, train_acc: 0.9282833333333333, test_loss: 0.33650509975850584, test_acc: 0.8842\n",
      "[0.8796, 0.8852, 0.8812] 0\n",
      "trainer_name: sgd, glob_circle: 0, lr: 0.001, ep: 8, train_loss: 0.1688305415371631, train_acc: 0.9370166666666667, test_loss: 0.31544245444238184, test_acc: 0.8897\n",
      "[0.8852, 0.8812, 0.8842] 1\n",
      "trainer_name: sgd, glob_circle: 0, lr: 0.001, ep: 9, train_loss: 0.15916715467229803, train_acc: 0.94195, test_loss: 0.3100536782294512, test_acc: 0.8932\n",
      "[0.8812, 0.8842, 0.8897] 0\n",
      "trainer_name: sgd, glob_circle: 1, lr: 0.001, ep: 0, train_loss: 0.15449234802038112, train_acc: 0.9440833333333334, test_loss: 0.3091138504445553, test_acc: 0.8919\n",
      "[0.8842, 0.8897, 0.8932] 0\n",
      "trainer_name: sgd, glob_circle: 1, lr: 0.001, ep: 1, train_loss: 0.15247284516375115, train_acc: 0.9455, test_loss: 0.3136226341128349, test_acc: 0.8928\n",
      "[0.8897, 0.8932, 0.8919] 0\n",
      "trainer_name: adam, glob_circle: 1, lr: 0.001, ep: 2, train_loss: 0.18052409471983605, train_acc: 0.93285, test_loss: 0.3255745619535446, test_acc: 0.8868\n",
      "[0.8932, 0.8919, 0.8928] 1\n",
      "trainer_name: sgd, glob_circle: 1, lr: 0.001, ep: 3, train_loss: 0.15297705607211337, train_acc: 0.94465, test_loss: 0.32281189523637294, test_acc: 0.8872\n",
      "[0.8919, 0.8928, 0.8868] 2\n",
      "trainer_name: adam, glob_circle: 1, lr: 0.001, ep: 4, train_loss: 0.16841092160407534, train_acc: 0.9369333333333333, test_loss: 0.33609782457351683, test_acc: 0.8865\n",
      "[0.8928, 0.8868, 0.8872] 3\n",
      "trainer_name: sgd, glob_circle: 1, lr: 0.001, ep: 5, train_loss: 0.14351794351922706, train_acc: 0.9481666666666667, test_loss: 0.3325039628893137, test_acc: 0.8931\n",
      "[0.8868, 0.8872, 0.8865] 4\n",
      "trainer_name: sgd, glob_circle: 1, lr: 0.001, ep: 6, train_loss: 0.13763259925106738, train_acc: 0.9494333333333334, test_loss: 0.3225067801773548, test_acc: 0.892\n",
      "[0.8872, 0.8865, 0.8931] 3\n",
      "trainer_name: sgd, glob_circle: 1, lr: 0.001, ep: 7, train_loss: 0.1345882718867444, train_acc: 0.9514, test_loss: 0.33341729566454886, test_acc: 0.8905\n",
      "[0.8865, 0.8931, 0.892] 2\n",
      "trainer_name: adam, glob_circle: 1, lr: 0.001, ep: 8, train_loss: 0.15905423398981702, train_acc: 0.9403333333333334, test_loss: 0.33231370896101, test_acc: 0.8936\n",
      "[0.8931, 0.892, 0.8905] 3\n",
      "trainer_name: adam, glob_circle: 1, lr: 0.001, ep: 9, train_loss: 0.14452873500103647, train_acc: 0.9472333333333334, test_loss: 0.35676528289914133, test_acc: 0.8869\n",
      "[0.892, 0.8905, 0.8936] 2\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 0, train_loss: 0.12402925679975367, train_acc: 0.95455, test_loss: 0.3398112621158361, test_acc: 0.8909\n",
      "[0.8905, 0.8936, 0.8869] 3\n",
      "trainer_name: adam, glob_circle: 2, lr: 0.001, ep: 1, train_loss: 0.14099568096881218, train_acc: 0.9460833333333334, test_loss: 0.3508647456765175, test_acc: 0.89\n",
      "[0.8936, 0.8869, 0.8909] 4\n",
      "trainer_name: adam, glob_circle: 2, lr: 0.001, ep: 2, train_loss: 0.12655989836822165, train_acc: 0.9530333333333333, test_loss: 0.3726504299789667, test_acc: 0.8865\n",
      "[0.8869, 0.8909, 0.89] 3\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 3, train_loss: 0.10778221976249776, train_acc: 0.9600166666666666, test_loss: 0.3651640098541975, test_acc: 0.8906\n",
      "[0.8909, 0.89, 0.8865] 4\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 4, train_loss: 0.10172510126486738, train_acc: 0.9626, test_loss: 0.3646877143532038, test_acc: 0.8905\n",
      "[0.89, 0.8865, 0.8906] 3\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 5, train_loss: 0.0989757665611328, train_acc: 0.9643666666666667, test_loss: 0.3573746342211962, test_acc: 0.8948\n",
      "[0.8865, 0.8906, 0.8905] 2\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 6, train_loss: 0.09636258638285576, train_acc: 0.9655333333333334, test_loss: 0.3512851405888796, test_acc: 0.8934\n",
      "[0.8906, 0.8905, 0.8948] 1\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 7, train_loss: 0.09402958546230133, train_acc: 0.9669666666666666, test_loss: 0.34199511259794235, test_acc: 0.8944\n",
      "[0.8905, 0.8948, 0.8934] 0\n",
      "trainer_name: adam, glob_circle: 2, lr: 0.001, ep: 8, train_loss: 0.12158688097558124, train_acc: 0.9549833333333333, test_loss: 0.3757839422672987, test_acc: 0.8838\n",
      "[0.8948, 0.8934, 0.8944] 1\n",
      "trainer_name: sgd, glob_circle: 2, lr: 0.001, ep: 9, train_loss: 0.10616156863088304, train_acc: 0.9607, test_loss: 0.3641879317350686, test_acc: 0.8896\n",
      "[0.8934, 0.8944, 0.8838] 2\n",
      "trainer_name: adam, glob_circle: 3, lr: 0.001, ep: 0, train_loss: 0.11481436093119865, train_acc: 0.95785, test_loss: 0.3890391603112221, test_acc: 0.8914\n",
      "[0.8944, 0.8838, 0.8896] 3\n",
      "trainer_name: adam, glob_circle: 3, lr: 0.001, ep: 1, train_loss: 0.10701368688902957, train_acc: 0.96075, test_loss: 0.39322790428996085, test_acc: 0.8865\n",
      "[0.8838, 0.8896, 0.8914] 2\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 2, train_loss: 0.09234486141420425, train_acc: 0.9666666666666667, test_loss: 0.3970335714519024, test_acc: 0.8922\n",
      "[0.8896, 0.8914, 0.8865] 3\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 3, train_loss: 0.08677968213215788, train_acc: 0.9691, test_loss: 0.38169562816619873, test_acc: 0.8903\n",
      "[0.8914, 0.8865, 0.8922] 2\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 4, train_loss: 0.08326110544990986, train_acc: 0.9701166666666666, test_loss: 0.37770392596721647, test_acc: 0.8902\n",
      "[0.8865, 0.8922, 0.8903] 1\n",
      "trainer_name: adam, glob_circle: 3, lr: 0.001, ep: 5, train_loss: 0.10191307608434494, train_acc: 0.9617333333333333, test_loss: 0.39186814837157724, test_acc: 0.8861\n",
      "[0.8922, 0.8903, 0.8902] 2\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 6, train_loss: 0.08539851437857811, train_acc: 0.96985, test_loss: 0.40630612559616563, test_acc: 0.8912\n",
      "[0.8903, 0.8902, 0.8861] 3\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 7, train_loss: 0.0787216324914009, train_acc: 0.9729833333333333, test_loss: 0.40419149920344355, test_acc: 0.8899\n",
      "[0.8902, 0.8861, 0.8912] 2\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 8, train_loss: 0.07545140789861375, train_acc: 0.97465, test_loss: 0.37394125759601593, test_acc: 0.8926\n",
      "[0.8861, 0.8912, 0.8899] 1\n",
      "trainer_name: sgd, glob_circle: 3, lr: 0.001, ep: 9, train_loss: 0.07353143199010098, train_acc: 0.9748333333333333, test_loss: 0.3703006783965975, test_acc: 0.8909\n",
      "[0.8912, 0.8899, 0.8926] 0\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 0, train_loss: 0.07137408036183804, train_acc: 0.9758666666666667, test_loss: 0.36731250397861004, test_acc: 0.893\n",
      "[0.8899, 0.8926, 0.8909] 0\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 1, train_loss: 0.06974319588947804, train_acc: 0.9768333333333333, test_loss: 0.3817553445696831, test_acc: 0.8922\n",
      "[0.8926, 0.8909, 0.893] 0\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 2, train_loss: 0.06861977811030885, train_acc: 0.9769666666666666, test_loss: 0.37247547656297686, test_acc: 0.8935\n",
      "[0.8909, 0.893, 0.8922] 0\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 3, train_loss: 0.06721853673299577, train_acc: 0.9783, test_loss: 0.3665692202746868, test_acc: 0.8958\n",
      "[0.893, 0.8922, 0.8935] 0\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 4, train_loss: 0.06652926739225996, train_acc: 0.97805, test_loss: 0.36287269089370966, test_acc: 0.8936\n",
      "[0.8922, 0.8935, 0.8958] 0\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 5, train_loss: 0.06543847433430083, train_acc: 0.9786166666666667, test_loss: 0.3784346718341112, test_acc: 0.8957\n",
      "[0.8935, 0.8958, 0.8936] 0\n",
      "trainer_name: adam, glob_circle: 4, lr: 0.001, ep: 6, train_loss: 0.099137910915182, train_acc: 0.96285, test_loss: 0.40158051401376726, test_acc: 0.8869\n",
      "[0.8958, 0.8936, 0.8957] 1\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 7, train_loss: 0.08031947069821206, train_acc: 0.9708166666666667, test_loss: 0.39813863337039945, test_acc: 0.8903\n",
      "[0.8936, 0.8957, 0.8869] 2\n",
      "trainer_name: adam, glob_circle: 4, lr: 0.001, ep: 8, train_loss: 0.09277826885276652, train_acc: 0.96505, test_loss: 0.41605503149330614, test_acc: 0.8864\n",
      "[0.8957, 0.8869, 0.8903] 3\n",
      "trainer_name: sgd, glob_circle: 4, lr: 0.001, ep: 9, train_loss: 0.07549339029541675, train_acc: 0.9722333333333333, test_loss: 0.4275999739766121, test_acc: 0.8883\n",
      "[0.8869, 0.8903, 0.8864] 4\n",
      "trainer_name: adam, glob_circle: 5, lr: 0.001, ep: 0, train_loss: 0.0888881910830102, train_acc: 0.96695, test_loss: 0.4159054532647133, test_acc: 0.8911\n",
      "[0.8903, 0.8864, 0.8883] 5\n",
      "trainer_name: adam, glob_circle: 5, lr: 0.001, ep: 1, train_loss: 0.08459984208358096, train_acc: 0.9686666666666667, test_loss: 0.45799247473478316, test_acc: 0.888\n",
      "[0.8864, 0.8883, 0.8911] 4\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 2, train_loss: 0.07439622892502774, train_acc: 0.9726666666666667, test_loss: 0.42416009642183783, test_acc: 0.8925\n",
      "[0.8883, 0.8911, 0.888] 5\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 3, train_loss: 0.06763784558849131, train_acc: 0.9754833333333334, test_loss: 0.4248560957610607, test_acc: 0.8922\n",
      "[0.8911, 0.888, 0.8925] 4\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 4, train_loss: 0.06396593527590975, train_acc: 0.977, test_loss: 0.4112416435033083, test_acc: 0.8942\n",
      "[0.888, 0.8925, 0.8922] 3\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 5, train_loss: 0.061197843077652, train_acc: 0.9784333333333334, test_loss: 0.42741777896881106, test_acc: 0.8947\n",
      "[0.8925, 0.8922, 0.8942] 2\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 6, train_loss: 0.058319325951185635, train_acc: 0.9798666666666667, test_loss: 0.407505190372467, test_acc: 0.8949\n",
      "[0.8922, 0.8942, 0.8947] 1\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 7, train_loss: 0.056417790514991635, train_acc: 0.9806666666666667, test_loss: 0.40738743878901007, test_acc: 0.8944\n",
      "[0.8942, 0.8947, 0.8949] 0\n",
      "trainer_name: adam, glob_circle: 5, lr: 0.001, ep: 8, train_loss: 0.0811734251043898, train_acc: 0.9696333333333333, test_loss: 0.47255667969584464, test_acc: 0.8861\n",
      "[0.8947, 0.8949, 0.8944] 1\n",
      "trainer_name: sgd, glob_circle: 5, lr: 0.001, ep: 9, train_loss: 0.06996510904678639, train_acc: 0.97415, test_loss: 0.4421470627188683, test_acc: 0.888\n",
      "[0.8949, 0.8944, 0.8861] 2\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 0, train_loss: 0.07743644045388445, train_acc: 0.9705666666666667, test_loss: 0.47390366569161413, test_acc: 0.8871\n",
      "[0.8944, 0.8861, 0.888] 3\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 1, train_loss: 0.0677128182129657, train_acc: 0.9751, test_loss: 0.47475294172763827, test_acc: 0.889\n",
      "[0.8861, 0.888, 0.8871] 2\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 2, train_loss: 0.06504383543704419, train_acc: 0.9758333333333333, test_loss: 0.4770941697061062, test_acc: 0.8896\n",
      "[0.888, 0.8871, 0.889] 1\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 3, train_loss: 0.06378232470535218, train_acc: 0.97585, test_loss: 0.49046982228755953, test_acc: 0.8898\n",
      "[0.8871, 0.889, 0.8896] 0\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 4, train_loss: 0.059452410502002596, train_acc: 0.9778666666666667, test_loss: 0.4823459282517433, test_acc: 0.8939\n",
      "[0.889, 0.8896, 0.8898] 0\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 5, train_loss: 0.06010363959568612, train_acc: 0.9785166666666667, test_loss: 0.46011134162545203, test_acc: 0.8906\n",
      "[0.8896, 0.8898, 0.8939] 0\n",
      "trainer_name: adam, glob_circle: 6, lr: 0.001, ep: 6, train_loss: 0.05383435791318721, train_acc: 0.98115, test_loss: 0.5042612329125404, test_acc: 0.8893\n",
      "[0.8898, 0.8939, 0.8906] 0\n",
      "trainer_name: sgd, glob_circle: 6, lr: 0.001, ep: 7, train_loss: 0.045613738284149066, train_acc: 0.9844333333333334, test_loss: 0.47681761011481283, test_acc: 0.8909\n",
      "[0.8939, 0.8906, 0.8893] 1\n",
      "trainer_name: sgd, glob_circle: 6, lr: 0.001, ep: 8, train_loss: 0.04210952751417743, train_acc: 0.98575, test_loss: 0.5039836719632149, test_acc: 0.8931\n",
      "[0.8906, 0.8893, 0.8909] 0\n",
      "trainer_name: sgd, glob_circle: 6, lr: 0.001, ep: 9, train_loss: 0.03999285038481368, train_acc: 0.9867, test_loss: 0.47714911587536335, test_acc: 0.8926\n",
      "[0.8893, 0.8909, 0.8931] 0\n",
      "trainer_name: sgd, glob_circle: 7, lr: 0.001, ep: 0, train_loss: 0.03689211466290215, train_acc: 0.98825, test_loss: 0.4845246344804764, test_acc: 0.8912\n",
      "[0.8909, 0.8931, 0.8926] 0\n",
      "trainer_name: adam, glob_circle: 7, lr: 0.001, ep: 1, train_loss: 0.0564079787740682, train_acc: 0.9793333333333333, test_loss: 0.5099074586760253, test_acc: 0.8853\n",
      "[0.8931, 0.8926, 0.8912] 1\n",
      "trainer_name: sgd, glob_circle: 7, lr: 0.001, ep: 2, train_loss: 0.04799427711503937, train_acc: 0.98295, test_loss: 0.5367623843252659, test_acc: 0.8847\n",
      "[0.8926, 0.8912, 0.8853] 2\n",
      "trainer_name: adam, glob_circle: 7, lr: 0.001, ep: 3, train_loss: 0.055103842985439806, train_acc: 0.9797333333333333, test_loss: 0.523398157954216, test_acc: 0.8878\n",
      "[0.8912, 0.8853, 0.8847] 3\n",
      "trainer_name: adam, glob_circle: 7, lr: 0.001, ep: 4, train_loss: 0.047486840529327695, train_acc: 0.9824666666666667, test_loss: 0.5708727322518825, test_acc: 0.8857\n",
      "[0.8853, 0.8847, 0.8878] 2\n",
      "trainer_name: adam, glob_circle: 7, lr: 0.001, ep: 5, train_loss: 0.04903794049899629, train_acc: 0.9822, test_loss: 0.5293053716421128, test_acc: 0.8842\n",
      "[0.8847, 0.8878, 0.8857] 1\n",
      "trainer_name: sgd, glob_circle: 7, lr: 0.001, ep: 6, train_loss: 0.046112172737559104, train_acc: 0.983, test_loss: 0.5416900262236595, test_acc: 0.8874\n",
      "[0.8878, 0.8857, 0.8842] 2\n",
      "trainer_name: sgd, glob_circle: 7, lr: 0.001, ep: 7, train_loss: 0.040452427341741454, train_acc: 0.9850833333333333, test_loss: 0.5261412516236306, test_acc: 0.8879\n",
      "[0.8857, 0.8842, 0.8874] 1\n",
      "trainer_name: sgd, glob_circle: 7, lr: 0.001, ep: 8, train_loss: 0.03790090017496271, train_acc: 0.98645, test_loss: 0.5087085351347923, test_acc: 0.8887\n",
      "[0.8842, 0.8874, 0.8879] 0\n",
      "trainer_name: sgd, glob_circle: 7, lr: 0.001, ep: 9, train_loss: 0.035019013305452276, train_acc: 0.9877, test_loss: 0.5190209694206714, test_acc: 0.891\n",
      "[0.8874, 0.8879, 0.8887] 0\n",
      "trainer_name: sgd, glob_circle: 8, lr: 0.001, ep: 0, train_loss: 0.033925751398535486, train_acc: 0.9883333333333333, test_loss: 0.5089298278093338, test_acc: 0.8907\n",
      "[0.8879, 0.8887, 0.891] 0\n",
      "trainer_name: sgd, glob_circle: 8, lr: 0.001, ep: 1, train_loss: 0.03164525689517564, train_acc: 0.9889833333333333, test_loss: 0.5139209032058716, test_acc: 0.8935\n",
      "[0.8887, 0.891, 0.8907] 0\n",
      "trainer_name: sgd, glob_circle: 8, lr: 0.001, ep: 2, train_loss: 0.031226036935410602, train_acc: 0.9893333333333333, test_loss: 0.4970412001013756, test_acc: 0.892\n",
      "[0.891, 0.8907, 0.8935] 0\n",
      "trainer_name: sgd, glob_circle: 8, lr: 0.001, ep: 3, train_loss: 0.030676468453825788, train_acc: 0.9902, test_loss: 0.5289224624633789, test_acc: 0.8917\n",
      "[0.8907, 0.8935, 0.892] 0\n",
      "trainer_name: adam, glob_circle: 8, lr: 0.001, ep: 4, train_loss: 0.04943652766499113, train_acc: 0.9813, test_loss: 0.5172731393948198, test_acc: 0.8898\n",
      "[0.8935, 0.892, 0.8917] 1\n",
      "trainer_name: sgd, glob_circle: 8, lr: 0.001, ep: 5, train_loss: 0.03868062562764959, train_acc: 0.98685, test_loss: 0.5371146686375141, test_acc: 0.888\n",
      "[0.892, 0.8917, 0.8898] 2\n",
      "trainer_name: adam, glob_circle: 8, lr: 0.001, ep: 6, train_loss: 0.04774196359150587, train_acc: 0.9820166666666666, test_loss: 0.532775616273284, test_acc: 0.8873\n",
      "[0.8917, 0.8898, 0.888] 3\n",
      "trainer_name: sgd, glob_circle: 8, lr: 0.001, ep: 7, train_loss: 0.04025313251037547, train_acc: 0.9859, test_loss: 0.5346679978072644, test_acc: 0.887\n",
      "[0.8898, 0.888, 0.8873] 4\n",
      "trainer_name: adam, glob_circle: 8, lr: 0.001, ep: 8, train_loss: 0.044203445148911884, train_acc: 0.984, test_loss: 0.5547200597822666, test_acc: 0.8886\n",
      "[0.888, 0.8873, 0.887] 5\n",
      "trainer_name: adam, glob_circle: 8, lr: 0.001, ep: 9, train_loss: 0.04248713784791688, train_acc: 0.9842833333333333, test_loss: 0.5943769499659538, test_acc: 0.889\n",
      "[0.8873, 0.887, 0.8886] 4\n",
      "trainer_name: adam, glob_circle: 9, lr: 0.001, ep: 0, train_loss: 0.043159961874814745, train_acc: 0.98445, test_loss: 0.571130596846342, test_acc: 0.8888\n",
      "[0.887, 0.8886, 0.889] 3\n",
      "trainer_name: adam, glob_circle: 9, lr: 0.001, ep: 1, train_loss: 0.03448093027034973, train_acc: 0.9873, test_loss: 0.5700393080711365, test_acc: 0.8859\n",
      "[0.8886, 0.889, 0.8888] 2\n",
      "trainer_name: sgd, glob_circle: 9, lr: 0.001, ep: 2, train_loss: 0.027977070152918074, train_acc: 0.9907333333333334, test_loss: 0.5619997747242451, test_acc: 0.8888\n",
      "[0.889, 0.8888, 0.8859] 3\n",
      "trainer_name: adam, glob_circle: 9, lr: 0.001, ep: 3, train_loss: 0.040656220611739666, train_acc: 0.9849, test_loss: 0.5696034006774425, test_acc: 0.8904\n",
      "[0.8888, 0.8859, 0.8888] 4\n",
      "trainer_name: adam, glob_circle: 9, lr: 0.001, ep: 4, train_loss: 0.03600407483333603, train_acc: 0.9864833333333334, test_loss: 0.5751391855999828, test_acc: 0.8892\n",
      "[0.8859, 0.8888, 0.8904] 3\n",
      "trainer_name: adam, glob_circle: 9, lr: 0.001, ep: 5, train_loss: 0.037037365423872114, train_acc: 0.9859333333333333, test_loss: 0.6100700773298741, test_acc: 0.89\n",
      "[0.8888, 0.8904, 0.8892] 2\n",
      "trainer_name: sgd, glob_circle: 9, lr: 0.001, ep: 6, train_loss: 0.030620614098424606, train_acc: 0.98875, test_loss: 0.6162276610732078, test_acc: 0.8912\n",
      "[0.8904, 0.8892, 0.89] 3\n",
      "trainer_name: sgd, glob_circle: 9, lr: 0.001, ep: 7, train_loss: 0.0289232319617208, train_acc: 0.98995, test_loss: 0.6019366726279258, test_acc: 0.89\n",
      "[0.8892, 0.89, 0.8912] 2\n",
      "trainer_name: adam, glob_circle: 9, lr: 0.001, ep: 8, train_loss: 0.03665887115998788, train_acc: 0.9865333333333334, test_loss: 0.6251373052597046, test_acc: 0.8855\n",
      "[0.89, 0.8912, 0.89] 3\n",
      "trainer_name: sgd, glob_circle: 9, lr: 0.001, ep: 9, train_loss: 0.028960551759426263, train_acc: 0.9898333333333333, test_loss: 0.6025555647909642, test_acc: 0.8885\n",
      "[0.8912, 0.89, 0.8855] 4\n",
      "trainer_name: adam, glob_circle: 10, lr: 0.001, ep: 0, train_loss: 0.0373704228034996, train_acc: 0.98635, test_loss: 0.6066566735506058, test_acc: 0.8921\n",
      "[0.89, 0.8855, 0.8885] 5\n",
      "trainer_name: adam, glob_circle: 10, lr: 0.001, ep: 1, train_loss: 0.03265030330760365, train_acc: 0.9883833333333333, test_loss: 0.5917614221572876, test_acc: 0.8912\n",
      "[0.8855, 0.8885, 0.8921] 4\n",
      "trainer_name: adam, glob_circle: 10, lr: 0.001, ep: 2, train_loss: 0.034379565678140586, train_acc: 0.9873666666666666, test_loss: 0.6482834629714489, test_acc: 0.8901\n",
      "[0.8885, 0.8921, 0.8912] 3\n",
      "trainer_name: sgd, glob_circle: 10, lr: 0.001, ep: 3, train_loss: 0.02565464139618772, train_acc: 0.9911833333333333, test_loss: 0.589847631752491, test_acc: 0.8906\n",
      "[0.8921, 0.8912, 0.8901] 4\n",
      "trainer_name: adam, glob_circle: 10, lr: 0.001, ep: 4, train_loss: 0.03179465512091175, train_acc: 0.98855, test_loss: 0.6172270901501179, test_acc: 0.8882\n",
      "[0.8912, 0.8901, 0.8906] 5\n",
      "trainer_name: sgd, glob_circle: 11, lr: 0.0005, ep: 0, train_loss: 0.022897662131234685, train_acc: 0.9920833333333333, test_loss: 0.6262910291552544, test_acc: 0.8862\n",
      "[0.8901, 0.8906, 0.8882] 0\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 1, train_loss: 0.016532321786507966, train_acc: 0.9945833333333334, test_loss: 0.614145539700985, test_acc: 0.8922\n",
      "[0.8906, 0.8882, 0.8862] 1\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 2, train_loss: 0.011639455724705724, train_acc: 0.9964833333333334, test_loss: 0.6348228130489588, test_acc: 0.8933\n",
      "[0.8882, 0.8862, 0.8922] 0\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 3, train_loss: 0.011930139220636734, train_acc: 0.9965333333333334, test_loss: 0.6630371533334255, test_acc: 0.8932\n",
      "[0.8862, 0.8922, 0.8933] 0\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 4, train_loss: 0.011039652343978114, train_acc: 0.9965833333333334, test_loss: 0.6525282084941864, test_acc: 0.8937\n",
      "[0.8922, 0.8933, 0.8932] 0\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 5, train_loss: 0.0125183016785044, train_acc: 0.9959, test_loss: 0.6916356444358825, test_acc: 0.8919\n",
      "[0.8933, 0.8932, 0.8937] 0\n",
      "trainer_name: sgd, glob_circle: 11, lr: 0.0005, ep: 6, train_loss: 0.008404795653087662, train_acc: 0.99775, test_loss: 0.6556636795401574, test_acc: 0.8932\n",
      "[0.8932, 0.8937, 0.8919] 1\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 7, train_loss: 0.01181844064143506, train_acc: 0.9960666666666667, test_loss: 0.6863898433744907, test_acc: 0.8914\n",
      "[0.8937, 0.8919, 0.8932] 2\n",
      "trainer_name: sgd, glob_circle: 11, lr: 0.0005, ep: 8, train_loss: 0.008415532330090696, train_acc: 0.9974833333333334, test_loss: 0.7061800681054592, test_acc: 0.8909\n",
      "[0.8919, 0.8932, 0.8914] 3\n",
      "trainer_name: adam, glob_circle: 11, lr: 0.0005, ep: 9, train_loss: 0.011369074359437095, train_acc: 0.99655, test_loss: 0.6923134438693523, test_acc: 0.8897\n",
      "[0.8932, 0.8914, 0.8909] 4\n",
      "trainer_name: sgd, glob_circle: 12, lr: 0.0005, ep: 0, train_loss: 0.010885917120662697, train_acc: 0.99655, test_loss: 0.6727167144417763, test_acc: 0.8913\n",
      "[0.8914, 0.8909, 0.8897] 5\n",
      "trainer_name: sgd, glob_circle: 12, lr: 0.0005, ep: 1, train_loss: 0.010317361529203171, train_acc: 0.9968166666666667, test_loss: 0.6782522916793823, test_acc: 0.8918\n",
      "[0.8909, 0.8897, 0.8913] 4\n",
      "trainer_name: sgd, glob_circle: 12, lr: 0.0005, ep: 2, train_loss: 0.009738237312202282, train_acc: 0.9969833333333333, test_loss: 0.6709575541317463, test_acc: 0.8936\n",
      "[0.8897, 0.8913, 0.8918] 3\n",
      "trainer_name: sgd, glob_circle: 12, lr: 0.0005, ep: 3, train_loss: 0.009117548215262433, train_acc: 0.9975, test_loss: 0.6692828749946784, test_acc: 0.8924\n",
      "[0.8913, 0.8918, 0.8936] 2\n",
      "trainer_name: sgd, glob_circle: 12, lr: 0.0005, ep: 4, train_loss: 0.008699166649417516, train_acc: 0.9976333333333334, test_loss: 0.6680003691464662, test_acc: 0.8933\n",
      "[0.8918, 0.8936, 0.8924] 1\n",
      "trainer_name: adam, glob_circle: 12, lr: 0.0005, ep: 5, train_loss: 0.011745344324314847, train_acc: 0.996, test_loss: 0.7090968601405621, test_acc: 0.8933\n",
      "[0.8936, 0.8924, 0.8933] 2\n",
      "trainer_name: adam, glob_circle: 12, lr: 0.0005, ep: 6, train_loss: 0.010482993351414482, train_acc: 0.9969833333333333, test_loss: 0.784212988615036, test_acc: 0.8905\n",
      "[0.8924, 0.8933, 0.8933] 1\n",
      "trainer_name: sgd, glob_circle: 12, lr: 0.0005, ep: 7, train_loss: 0.008636001700119293, train_acc: 0.9975, test_loss: 0.698591523617506, test_acc: 0.8895\n",
      "[0.8933, 0.8933, 0.8905] 2\n",
      "trainer_name: adam, glob_circle: 12, lr: 0.0005, ep: 8, train_loss: 0.010940346158446466, train_acc: 0.9965833333333334, test_loss: 0.690292326360941, test_acc: 0.8938\n",
      "[0.8933, 0.8905, 0.8895] 3\n",
      "trainer_name: adam, glob_circle: 12, lr: 0.0005, ep: 9, train_loss: 0.008927952317877652, train_acc: 0.9972833333333333, test_loss: 0.7913352563977242, test_acc: 0.8935\n",
      "[0.8905, 0.8895, 0.8938] 2\n",
      "trainer_name: adam, glob_circle: 13, lr: 0.0005, ep: 0, train_loss: 0.01013505991444269, train_acc: 0.9965333333333334, test_loss: 0.7328491322696209, test_acc: 0.8931\n",
      "[0.8895, 0.8938, 0.8935] 1\n",
      "trainer_name: sgd, glob_circle: 13, lr: 0.0005, ep: 1, train_loss: 0.008213043840294903, train_acc: 0.9975333333333334, test_loss: 0.7092250235378742, test_acc: 0.8921\n",
      "[0.8938, 0.8935, 0.8931] 2\n",
      "trainer_name: adam, glob_circle: 13, lr: 0.0005, ep: 2, train_loss: 0.01058535634520206, train_acc: 0.9966, test_loss: 0.7511926777660847, test_acc: 0.8944\n",
      "[0.8935, 0.8931, 0.8921] 3\n",
      "trainer_name: adam, glob_circle: 13, lr: 0.0005, ep: 3, train_loss: 0.009829713307826364, train_acc: 0.99685, test_loss: 0.7524761885404587, test_acc: 0.8921\n",
      "[0.8931, 0.8921, 0.8944] 2\n",
      "trainer_name: sgd, glob_circle: 13, lr: 0.0005, ep: 4, train_loss: 0.008288902163188509, train_acc: 0.9975166666666667, test_loss: 0.7429748494178057, test_acc: 0.8914\n",
      "[0.8921, 0.8944, 0.8921] 3\n",
      "trainer_name: adam, glob_circle: 13, lr: 0.0005, ep: 5, train_loss: 0.009046768560817346, train_acc: 0.9970333333333333, test_loss: 0.7725784905254841, test_acc: 0.8906\n",
      "[0.8944, 0.8921, 0.8914] 4\n",
      "trainer_name: sgd, glob_circle: 13, lr: 0.0005, ep: 6, train_loss: 0.007621037329675907, train_acc: 0.9978, test_loss: 0.7476616360247135, test_acc: 0.8928\n",
      "[0.8921, 0.8914, 0.8906] 5\n",
      "trainer_name: sgd, glob_circle: 13, lr: 0.0005, ep: 7, train_loss: 0.0077972591899216495, train_acc: 0.9975166666666667, test_loss: 0.7777215421199799, test_acc: 0.8909\n",
      "[0.8914, 0.8906, 0.8928] 4\n",
      "trainer_name: sgd, glob_circle: 13, lr: 0.0005, ep: 8, train_loss: 0.007050467131936804, train_acc: 0.9978833333333333, test_loss: 0.7486814603209495, test_acc: 0.8921\n",
      "[0.8906, 0.8928, 0.8909] 3\n",
      "trainer_name: adam, glob_circle: 13, lr: 0.0005, ep: 9, train_loss: 0.0091846940949797, train_acc: 0.9969333333333333, test_loss: 0.7954503744840622, test_acc: 0.8914\n",
      "[0.8928, 0.8909, 0.8921] 4\n",
      "trainer_name: adam, glob_circle: 14, lr: 0.0005, ep: 0, train_loss: 0.009357808497139906, train_acc: 0.9967666666666667, test_loss: 0.7746747180819511, test_acc: 0.8907\n",
      "[0.8909, 0.8921, 0.8914] 3\n",
      "trainer_name: sgd, glob_circle: 14, lr: 0.0005, ep: 1, train_loss: 0.008453667156913496, train_acc: 0.9973, test_loss: 0.7584304541349411, test_acc: 0.8923\n",
      "[0.8921, 0.8914, 0.8907] 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-49d0f62052ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m           \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    #torch.nn.Dropout(p=0.15),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.BatchNorm1d(784),\n",
    "    torch.nn.Linear(784, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    #torch.nn.Dropout(p=0.3),\n",
    "    torch.nn.BatchNorm1d(64),\n",
    "    torch.nn.Linear(64, 10)\n",
    ")\n",
    "print(model)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "l_lr = 0.001\n",
    "num_glob_circle = 100\n",
    "num_epochs = 10\n",
    "\n",
    "l_prev_acc = [0]*3 # array to gather statistics of last 5 steps' test-accuracy to do smth - change trainer or learning rate\n",
    "l_tries_max = 5 # max count of tries to not changing learning rate and to change trainer\n",
    "l_tries = 0 # count of tries\n",
    "trainer, trainer_name = torch.optim.Adam(model.parameters(), lr=l_lr), 'adam'\n",
    "#trainer, trainer_name = torch.optim.SGD(model.parameters(), lr=l_lr), 'sgd'\n",
    "for glob_circle in range(num_glob_circle):\n",
    "\n",
    "  for ep in range(num_epochs):\n",
    "      train_iters, train_passed  = 0, 0\n",
    "      train_loss, train_acc = 0., 0.\n",
    "      \n",
    "      for X, y in train:\n",
    "          trainer.zero_grad()\n",
    "          y_pred = model(X)\n",
    "          l = loss(y_pred, y)\n",
    "          l.backward()\n",
    "          trainer.step()\n",
    "          train_loss += l.item()\n",
    "          train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "          train_iters += 1\n",
    "          train_passed += len(X)\n",
    "      \n",
    "      test_iters, test_passed  = 0, 0\n",
    "      test_loss, test_acc = 0., 0.\n",
    "      for X, y in test:\n",
    "          y_pred = model(X)\n",
    "          l = loss(y_pred, y)\n",
    "          test_loss += l.item()\n",
    "          test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "          test_iters += 1\n",
    "          test_passed += len(X)\n",
    "          \n",
    "      print(\"trainer_name: {}, glob_circle: {}, lr: {}, ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "          trainer_name, glob_circle, l_lr, ep, train_loss / train_iters, train_acc / train_passed,\n",
    "          test_loss / test_iters, test_acc / test_passed)\n",
    "      )\n",
    "      print(l_prev_acc, l_tries)\n",
    "      l_prev_acc.append(test_acc / test_passed)\n",
    "      del l_prev_acc[0]\n",
    "      \n",
    "      if test_acc / test_passed > l_prev_acc[0]:\n",
    "        l_tries -= 1 if l_tries > 0 else 0\n",
    "      else:\n",
    "        l_tries += 1\n",
    "        if trainer_name == 'sgd':\n",
    "            trainer, trainer_name = torch.optim.Adam(model.parameters(), lr=l_lr), 'adam'\n",
    "        else:\n",
    "            trainer, trainer_name = torch.optim.SGD(model.parameters(), lr=l_lr), 'sgd'\n",
    "\n",
    "        if l_tries > l_tries_max:\n",
    "            l_lr = l_lr / 2\n",
    "            l_tries = 0\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
