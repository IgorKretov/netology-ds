{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "* Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "* Реализовать самостоятельно логистическую регрессию\n",
    "    * Обучить ее методом градиентного спуска\n",
    "    * Методом nesterov momentum\n",
    "    * Методом rmsprop\n",
    "* В качестве dataset'а взять Iris, оставив 2 класса:\n",
    "    * Iris Versicolor\n",
    "    * Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(load_iris()['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris().data\n",
    "feature_names = load_iris().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = load_iris().target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Так как нас интересуют только два класса: Versicolor, Virginica, то уберем те строчки, где target == 0 (это класс setosa).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['target']==1) | (df['target']==2)].reset_index().drop(columns=['index'])\n",
    "df['target'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr = X_train.transpose()\n",
    "y_train_tr = np.array(y_train).reshape(1,y_train.shape[0])\n",
    "X_test_tr = X_test.transpose()\n",
    "y_test_tr = np.array(y_test).reshape(1,y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализуем самостоятельно логистическую регрессию и сравним результаты с LogisticRegression из sklearn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegression():\n",
    "    \n",
    "    def __init__(self, num_iterations=1000, learning_rate=0.01, method='gb', gamma=None, eps=None):\n",
    "        \"\"\"\n",
    "        num_iterations - количество итераций цикла оптимизации\n",
    "        learning_rate - скорость обучения\n",
    "        method - метод оптимизации\n",
    "        \"\"\"\n",
    "        self.num_iterations = num_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.method = method\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "\n",
    "        s = 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "        return s\n",
    "\n",
    "    def propagate(self, w, b, X, Y):\n",
    "        \"\"\"\n",
    "        Реализует функцию стоимости и ее градиент.\n",
    "        Принимает на вход:\n",
    "        w - веса\n",
    "        б - смещение, скаляр\n",
    "        X - наши данные \n",
    "        Y - целевая функция\n",
    "\n",
    "        Возвращает:\n",
    "        cost - отрицательная логарифмическая вероятность для логистической регрессии\n",
    "        dw - градиент w\n",
    "        db - градиент b\n",
    "        \"\"\"\n",
    "        \n",
    "        number_of_features = X.shape[1]\n",
    "        z = np.dot(w.T,X)+b\n",
    "        A = self.sigmoid(z)\n",
    "        #cost = -1.0/number_of_features*np.sum(Y*np.log(A)+(1.0-Y)*np.log(1.0-A))\n",
    "\n",
    "        dw = 1.0/number_of_features*np.dot(X, (A-Y).T)\n",
    "        db = 1.0/number_of_features*np.sum(A-Y)\n",
    "\n",
    "        #cost = np.squeeze(cost)\n",
    "\n",
    "        grads = {\"dw\": dw, \n",
    "                 \"db\":db}\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def optimize(self, X, Y, method):\n",
    "        \"\"\"\n",
    "        Этот метод оптимизирует w и b, различными алгоритмами. (Гр. спуск, nesterov momentum, rmsprop)\n",
    "\n",
    "        Принимает на вход:\n",
    "        w - веса\n",
    "        б - смещение, скаляр\n",
    "        X - наши данные\n",
    "        Y - целевая функция\n",
    "        num_iterations - количество итераций цикла оптимизации\n",
    "        learning_rate - скорость обучения правила обновления градиентного спуска\n",
    "        \n",
    "        Возвращает:\n",
    "        params - словарь, содержащий веса w и смещение b\n",
    "        grads - словарь, содержащий градиенты весов и смещений\n",
    "        \"\"\"\n",
    "        w = np.zeros((X.shape[0],1))\n",
    "        b = 0\n",
    "\n",
    "        costs = []\n",
    "        \n",
    "        if self.method == 'gb':\n",
    "\n",
    "            for i in range(self.num_iterations):\n",
    "\n",
    "                grads = self.propagate(w, b, X, Y)\n",
    "\n",
    "                dw = grads[\"dw\"]\n",
    "                db = grads[\"db\"]\n",
    "\n",
    "                w = w - self.learning_rate*dw\n",
    "                b = b - self.learning_rate*db\n",
    "        \n",
    "        elif self.method == 'nm':\n",
    "            v_w = 0\n",
    "            v_b = 0\n",
    "            for i in range(self.num_iterations):\n",
    "\n",
    "                grads = self.propagate(w, b, X, Y)\n",
    "\n",
    "                dw = grads[\"dw\"]\n",
    "                db = grads[\"db\"]\n",
    "\n",
    "                v_w = self.gamma*v_w + self.learning_rate*(1-self.gamma)*dw\n",
    "                \n",
    "                v_b = self.gamma*v_b + self.learning_rate*(1-self.gamma)*db\n",
    "                \n",
    "                w = w - v_w\n",
    "                b = b - v_b\n",
    "                \n",
    "        elif self.method == 'rmsp':\n",
    "            EG_w = 0\n",
    "            EG_b = 0\n",
    "            for i in range(self.num_iterations):\n",
    "\n",
    "                grads = self.propagate(w, b, X, Y)\n",
    "\n",
    "                dw = grads[\"dw\"]\n",
    "                db = grads[\"db\"]\n",
    "\n",
    "                EG_w = self.gamma*EG_w + (1-self.gamma)*(dw/self.learning_rate)**2                \n",
    "                EG_b = self.gamma*EG_b + (1-self.gamma)*(db/self.learning_rate)**2\n",
    "                \n",
    "                w = w - dw/(EG_w + self.eps)**0.5\n",
    "                b = b - db/(EG_b + self.eps)**0.5\n",
    "\n",
    "        grads = {\"dw\": dw, \"db\": db}\n",
    "        params = {\"w\": w, \"b\": b}\n",
    "\n",
    "        return params\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self, w, b, X):\n",
    "        \"\"\"\n",
    "        Предсказывает будет значение 0 или 1 (граница 0.5).\n",
    "        \"\"\"\n",
    "\n",
    "        y_prediction = np.zeros((1,X.shape[1]))\n",
    "        w = w.reshape(X.shape[0],1)\n",
    "\n",
    "        A = self.sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "        for i in range(A.shape[1]):\n",
    "            if (A[:,i] > 0.5): \n",
    "                y_prediction[:, i] = 1\n",
    "            elif (A[:,i] <= 0.5):\n",
    "                y_prediction[:, i] = 0\n",
    "\n",
    "        return y_prediction[0]\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_test):\n",
    "        \"\"\"\n",
    "        Данный метод совершает оптимизацию и предсказывает значение y_test_predict.\n",
    "        \"\"\"\n",
    "        \n",
    "        parameters = self.optimize(X_train, y_train, self.method)\n",
    "\n",
    "        w = parameters[\"w\"]\n",
    "        b = parameters[\"b\"]\n",
    "\n",
    "        y_test_predict = self.predict(w, b, X_test)\n",
    "\n",
    "        return y_test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучим наши модели на разных способах оптимизации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rmsp = LogRegression(num_iterations=1000, learning_rate=0.02, method='rmsp', gamma=0.8, eps=1e-6)\n",
    "clf_gb = LogRegression(num_iterations=1000, learning_rate=0.02, method='gb')\n",
    "clf_nm = LogRegression(num_iterations=1000, learning_rate=0.02, method='nm', gamma=0.9)\n",
    "\n",
    "y_test_predict_rmsp = clf_rmsp.fit_predict(X_train_tr, y_train_tr, X_test_tr)\n",
    "y_test_predict_gb = clf_gb.fit_predict(X_train_tr, y_train_tr, X_test_tr)\n",
    "y_test_predict_nm = clf_nm.fit_predict(X_train_tr, y_train_tr, X_test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравним наши результаты на различных метриках.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [clf_rmsp, clf_gb, clf_nm, clf]\n",
    "y_preds = [y_test_predict_rmsp, y_test_predict_gb, y_test_predict_nm, y_test_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['LG_rmsp', 'LG_gb', 'LG_nm', 'LG_sklearn']\n",
    "metrics_columns = ['ROC_AUC', 'RECALL', 'ACCURACY', 'PRECISION', 'F1']\n",
    "metrics_scores = np.zeros(20).reshape(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, y_pred, metric_type):\n",
    "    \n",
    "    if metric_type == 'ROC_AUC':\n",
    "        return roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    elif metric_type == 'RECALL':\n",
    "        return recall_score(y_test, y_pred)\n",
    "    \n",
    "    elif metric_type == 'ACCURACY':\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    elif metric_type == 'PRECISION':\n",
    "        return precision_score(y_test, y_pred)\n",
    "    \n",
    "    elif metric_type == 'F1':\n",
    "        return f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классификатор: LG_rmsp, считаем метрики...\n",
      "Выполнено.\n",
      "Классификатор: LG_gb, считаем метрики...\n",
      "Выполнено.\n",
      "Классификатор: LG_nm, считаем метрики...\n",
      "Выполнено.\n",
      "Классификатор: LG_sklearn, считаем метрики...\n",
      "Выполнено.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(clfs)):  \n",
    "    print('Классификатор: {}, считаем метрики...'.format(index[i]))\n",
    "    for k in range(0, len(metrics_columns)):\n",
    "        metrics_scores[i][k] = metrics(y_test, y_preds[i], metric_type=metrics_columns[k])\n",
    "    print('Выполнено.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>ACCURACY</th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LG_rmsp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_gb</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_nm</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG_sklearn</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ROC_AUC  RECALL  ACCURACY  PRECISION        F1\n",
       "LG_rmsp     1.000000     1.0      1.00   1.000000  1.000000\n",
       "LG_gb       0.944444     1.0      0.95   0.916667  0.956522\n",
       "LG_nm       0.944444     1.0      0.95   0.916667  0.956522\n",
       "LG_sklearn  0.944444     1.0      0.95   0.916667  0.956522"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics_scores, index=index, columns=metrics_columns)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Таким образом, на некоторых данных одна из наших моделей показала результат даже лучший, чем из коробки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
