{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "https://github.com/maryszmary/nlp-netology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные задачи\n",
    "\n",
    "### Классификация текстов\n",
    "   * Фильтрация спама\n",
    "   * Анализ тональности\n",
    "   * Определение интента\n",
    "   * По теме или жанру\n",
    "   \n",
    "### Кластеризация текстов\n",
    "   * Аггрегация новостей\n",
    "   * Рекомендации\n",
    "   \n",
    "### Извлечение информации\n",
    "   * Именованные сущности (NER), отношения\n",
    "   * Факты и события   \n",
    "\n",
    "### Другие приложения\n",
    "   * Машинный перевод\n",
    "   * Вопросно-ответные системы\n",
    "   * Саммаризация текстов\n",
    "   * Генерация текста\n",
    "   * Распознавание речи\n",
    "   * Проверка правописания (spell-checking)\n",
    "   * Распознавание символов (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "![pipeline.png](nlp_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Обработка текста\n",
    "\n",
    "#### Уровень символов:\n",
    "   * Токенизация: разбиение текста на слова\n",
    "   * Разбиение текста на предложения\n",
    "   \n",
    "#### Уровень слов (морфология):\n",
    "   * Определение частей речи (POS-tagging)\n",
    "   * Снятие морфологической неоднозначности\n",
    "   \n",
    "#### Уровень предложений (синтаксис):\n",
    "   * Выделенние именных или глагольных групп (chunking)\n",
    "   * Выделенние семантических ролей\n",
    "   * Деревья составляющих и зависимостей\n",
    "   \n",
    "#### Уровень смысла (семантика и дискурс):\n",
    "   * Разрешение кореферентных связей\n",
    "   * Выделение синонимов\n",
    "   * Анализ аргументативных связей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные проблемы\n",
    "\n",
    "* Неоднозначность\n",
    "    * Лексическая неоднозначность: *орган, парить, рожки, атлас*\n",
    "    * Морфологическая неоднозначность: *Хранение денег в банке. Что делают белки в клетке?*\n",
    "    * Синтаксическая неоднозначность: *Его удивил простой солдат.*\n",
    "* Неологизмы: *печеньки, заинстаграммить, репостнуть, расшарить, затащить, килорубли*\n",
    "* Разные варианты написания: *Россия, Российская Федерация, РФ*\n",
    "* Нестандартное написание: *каг дила?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Синтаксическая неоднозначность\n",
    "\n",
    "### I saw a man on the hill with a telescope\n",
    "\n",
    "![syntax_ambiguaty](syntax_ambg.jpg)\n",
    "\n",
    "    I saw the man. The man was on the hill. I was using a telescope.\n",
    "    I saw the man. I was on the hill. I was using a telescope.\n",
    "    I saw the man. The man was on the hill. The hill had a telescope.\n",
    "    I saw the man. I was on the hill. The hill had a telescope.\n",
    "    I saw the man. The man was on the hill. I saw him using a telescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# План курса\n",
    "\n",
    "1. Предварительная обработка текстов\n",
    "2. Извлечение ключевых слов и синтаксический анализ \n",
    "3. Векторная модель, тематическое моделирование\n",
    "4. Векторная модель, дистрибутивная семантика\n",
    "5. Классификация текстов\n",
    "6. Языковые модели \n",
    "7. Извлечение информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная обработка текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-21 20:53:31--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2019-10-21 20:53:31--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc53a46f2263639e0da4990a1f05.dl.dropboxusercontent.com/cd/0/inline/Aq1gIYsNTKbZuJBNhCReACCwEe6pc5Hto80u7aviYD68IPgKgZ0c_aBIzxoLag16HnOQxBNPMUjrUhlnpGNh1ppdnF5onJRnqE-CouO4EqxePQ/file# [following]\n",
      "--2019-10-21 20:53:32--  https://uc53a46f2263639e0da4990a1f05.dl.dropboxusercontent.com/cd/0/inline/Aq1gIYsNTKbZuJBNhCReACCwEe6pc5Hto80u7aviYD68IPgKgZ0c_aBIzxoLag16HnOQxBNPMUjrUhlnpGNh1ppdnF5onJRnqE-CouO4EqxePQ/file\n",
      "Resolving uc53a46f2263639e0da4990a1f05.dl.dropboxusercontent.com (uc53a46f2263639e0da4990a1f05.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to uc53a46f2263639e0da4990a1f05.dl.dropboxusercontent.com (uc53a46f2263639e0da4990a1f05.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv’\n",
      "\n",
      "positive.csv        100%[===================>]  25,02M  10,1MB/s    in 2,5s    \n",
      "\n",
      "2019-10-21 20:53:36 (10,1 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
      "\n",
      "--2019-10-21 20:53:36--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2019-10-21 20:53:36--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucd7ce74bd0b4484c701e93d2ac1.dl.dropboxusercontent.com/cd/0/inline/Aq0702VAxOL71dj77sQMjgGcCbLNhXzI-PbgsgdGdYOBNEY_WrvQIGIkXEr4BIQkecmUfbiWBPO2y_5-k99KmnDqVGT4ipSnqKlQKP6_kpgddA/file# [following]\n",
      "--2019-10-21 20:53:37--  https://ucd7ce74bd0b4484c701e93d2ac1.dl.dropboxusercontent.com/cd/0/inline/Aq0702VAxOL71dj77sQMjgGcCbLNhXzI-PbgsgdGdYOBNEY_WrvQIGIkXEr4BIQkecmUfbiWBPO2y_5-k99KmnDqVGT4ipSnqKlQKP6_kpgddA/file\n",
      "Resolving ucd7ce74bd0b4484c701e93d2ac1.dl.dropboxusercontent.com (ucd7ce74bd0b4484c701e93d2ac1.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to ucd7ce74bd0b4484c701e93d2ac1.dl.dropboxusercontent.com (ucd7ce74bd0b4484c701e93d2ac1.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv’\n",
      "\n",
      "negative.csv        100%[===================>]  23,32M  6,67MB/s    in 3,6s    \n",
      "\n",
      "2019-10-21 20:53:41 (6,41 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>111918</td>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111919</td>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111920</td>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111921</td>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111922</td>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834, 2)\n",
      "(170125,)\n",
      "(56709,)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)',\n",
       " 'Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D',\n",
       " 'RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!',\n",
       " 'RT @digger2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" :DD http://t.co/GqG6iuE2…',\n",
       " '@irina_dyshkant Вот что значит страшилка :D\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :D']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ngram_range` отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "* ngram_range=(1, 1) -- униграммы<br/>\n",
    "* ngram_range=(3, 3) -- триграммы<br/>\n",
    "* ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В `vec.vocabulary_` лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('что', 237550),\n",
       " ('то', 222054),\n",
       " ('меня', 157647),\n",
       " ('на', 161767),\n",
       " ('смартфоне', 211437),\n",
       " ('кнопка', 145979),\n",
       " ('твит', 220411),\n",
       " ('вдруг', 110751),\n",
       " ('стала', 215846),\n",
       " ('работать', 199326),\n",
       " ('после', 190017),\n",
       " ('15', 962),\n",
       " ('года', 120565),\n",
       " ('нажатия', 162617),\n",
       " ('днище', 126410),\n",
       " ('rt', 74540),\n",
       " ('prisonero_o', 70400),\n",
       " ('тут', 224532),\n",
       " ('должна', 127386),\n",
       " ('быть', 109386)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.77     28423\n",
      "    positive       0.76      0.77      0.77     28286\n",
      "\n",
      "    accuracy                           0.77     56709\n",
      "   macro avg       0.77      0.77      0.77     56709\n",
      "weighted avg       0.77      0.77      0.77     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.72      0.56     18157\n",
      "    positive       0.82      0.61      0.70     38552\n",
      "\n",
      "    accuracy                           0.64     56709\n",
      "   macro avg       0.64      0.66      0.63     56709\n",
      "weighted avg       0.71      0.64      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26885\n",
      "    positive       0.78      0.75      0.76     29824\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось хуже :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26991\n",
      "    positive       0.78      0.75      0.76     29718\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), min_df=3, max_df=0.4)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@first_timee', 'хоть', 'я', 'и', 'школота,', 'но', 'поверь,', 'у', 'нас', 'то', 'же', 'самое', ':D', 'общество', 'профилирующий', 'предмет', 'типа)']\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_lilith_g',\n",
       " '0_о',\n",
       " '0bkpahm6ml',\n",
       " '0ddman0ut',\n",
       " '0imzp3crty',\n",
       " '0lexia0',\n",
       " '0pvgczivef',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000000',\n",
       " '1000р',\n",
       " '1001',\n",
       " '100500',\n",
       " '100lokal',\n",
       " '100гаруй',\n",
       " '100к',\n",
       " '100р']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разбивать текст на слова с использованием регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хоть я и школота но поверь у нас то же самое общество профилирующий предмет типа'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_only(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/truename/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', '9.5', 'or', '525,600', 'my', 'favorite', 'number', '?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WordPunctTokenizer']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 9.5 or 525,600 my favorite number ?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import toktok\n",
    "\n",
    "toktok = toktok.ToktokTokenizer()\n",
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "print (toktok.tokenize(text, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самые частотные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69267),\n",
       " ('и', 54916),\n",
       " ('в', 52853),\n",
       " ('я', 52506),\n",
       " ('RT', 38070),\n",
       " ('на', 35715),\n",
       " ('http', 32992),\n",
       " ('что', 31472),\n",
       " ('...', 28773),\n",
       " ('с', 27176),\n",
       " ('а', 26592),\n",
       " ('меня', 20591),\n",
       " ('у', 18861),\n",
       " ('как', 18141),\n",
       " ('так', 16739),\n",
       " ('D', 16552),\n",
       " ('это', 16436),\n",
       " ('мне', 16247),\n",
       " ('все', 14695),\n",
       " ('ты', 13358)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "\n",
    "# freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Ципфа\n",
    "Эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В любом достаточно большом тексте ранг слова обратно пропорционален его частоте: $f = \\frac{a}{r}$\n",
    "\n",
    "$f$ – частота слова, $r$  – ранг слова, $a$  – параметр, для славянских языков – около 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "freqs = list(freq_dict.values())\n",
    "freqs = sorted(freqs, reverse = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs[:300], range(300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Хипса\n",
    "\n",
    "С увеличением длины текста (количества токенов), количество слов увеличивается в соответствии с законом: $|V| = K*N^b$\n",
    "\n",
    "\n",
    "$N$  –  число токенов, $|V|$  – количество слов в словаре, $K, b$  –  параметры, обычно $K \\in [10,100], b \\in [0.4, 0.6]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226834/226834 [17:37<00:00, 214.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cnt = Counter()\n",
    "n_words = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    cnt.update([token for token in tokens if token not in punctuation])\n",
    "    n_words.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_tokens, n_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/truename/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (как написано выше)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29314\n",
      "    positive       0.76      0.79      0.78     27395\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "У каждого слова есть лемма (нормальная форма):\n",
    "\n",
    "    кошке, кошку, кошкам, кошкой ⟹ кошка\n",
    "    бежал, бежит, бегу ⟹ бежать\n",
    "    белому, белым, белыми ⟹ белый\n",
    "\n",
    "\n",
    "**Лемматизация** – это приведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/truename/anaconda3/lib/python3.7/site-packages (from pymystem3) (2.19.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/truename/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/truename/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/truename/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /home/truename/anaconda3/lib/python3.7/site-packages (from requests->pymystem3) (1.23)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /home/truename/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте терепь использовать лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords_ru = set(stopwords.words('russian'))\n",
    "stopwords_ru.update([' ', '\\n'])\n",
    "\n",
    "def my_preproc(text, stopwords = stopwords_ru):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.75      0.76     29332\n",
      "    positive       0.74      0.77      0.75     27377\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый, с большим количеством функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 529kB/s \n",
      "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 3.4MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/truename/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, pymorphy2-dicts, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'платили', 2368, 10),))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'Действительно, на его лице не отражалось никаких чувств – ни проблеска сочувствия не было на нем, а ведь боль просто невыносима'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на он лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на нем, а ведь боль просто невыносимый\n"
     ]
    }
   ],
   "source": [
    "lemmas1 = [pymorphy2_analyzer.parse(word)[0].normal_form for word in sent1.split()]\n",
    "print(' '.join(lemmas1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на его лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на немой, а ведь боль просто невыносимый\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmas2 = mystem_analyzer.lemmatize(sent1)\n",
    "print(''.join(lemmas2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Стемминг\n",
    "\n",
    "Слова состоят из морфем: 𝑤𝑜𝑟𝑑=𝑠𝑡𝑒𝑚+𝑎𝑓𝑓𝑖𝑥𝑒𝑠. Стемминг позволяет отбросить аффиксы. Чаще всего используется алгоритм Портера.\n",
    "\n",
    "Алгоритм Портера состоит из 5 циклов команд, на каждом цикле – операция удаления / замены суффикса. Возможны вероятностные расширения алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "распределен\n",
      "пристав\n",
      "сдела\n",
      "словообразован\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "stemmer = RussianStemmer()\n",
    "words = ['распределение', 'приставить', 'сделала', 'словообразование']\n",
    "for w in words:\n",
    "    stem = stemmer.stem(w)\n",
    "    print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     28162\n",
      "    positive       1.00      1.00      1.00     28547\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоило оставить пунктуацию -- и все метрики равны 1! Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70     52429\n",
      "    positive       0.15      1.00      0.26      4280\n",
      "\n",
      "    accuracy                           0.57     56709\n",
      "   macro avg       0.58      0.77      0.48     56709\n",
      "weighted avg       0.94      0.57      0.67     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ':D'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truename/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      1.00     28105\n",
      "    positive       1.00      0.99      1.00     28604\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы оказываются очень значимыми.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сегментация предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знаки \".\", \"?\", \"!\" не всегда однозначно определяют границы предложений.\n",
    "\n",
    "Бинарный классификатор для сегментации предложений: для каждой точки \".\" определить, является ли она концом предложения или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rusenttokenize\n",
      "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
      "Installing collected packages: rusenttokenize\n",
      "Successfully installed rusenttokenize-0.0.5\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rusenttokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Эта шоколадка за 400р.\n",
      "ничего из себя не представляла.\n",
      "В г.\n",
      "2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.\n",
      "\n",
      "3\n",
      "Эта шоколадка за 400р. ничего из себя не представляла.\n",
      "В г. 2019 Артём решил больше не ходить в этот магазин на берегу р.\n",
      "Москвы.\n"
     ]
    }
   ],
   "source": [
    "text = 'Эта шоколадка за 400р. ничего из себя не представляла. В г. 2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.'\n",
    "\n",
    "\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')\n",
    "\n",
    "print()\n",
    "sents = ru_sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регулярные выражения\n",
    "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Классы символов:*__\n",
    "\n",
    "__[A-Z]__ – символы верхнего регистра (латиница)\n",
    "\n",
    "__[a-z]__ – символы нижнего регистра (латиница)\n",
    "\n",
    "__[А-Я]__ – символы верхнего регистра (кириллица)\n",
    "\n",
    "__[а-я]__ – символы нижнего регистра (кириллица)\n",
    "\n",
    "__[0-9]__ или __\\d__ – цифра\n",
    "\n",
    "__[^0-9]__ или __\\D__ – любой символ, кроме цифры\n",
    "\n",
    "__.__ – любой символ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Служебные символы:*__\n",
    "\n",
    "__\\t__ – табуляция\n",
    "\n",
    "__\\s__ – любой пробельный символ\n",
    "\n",
    "__\\S__ – все символы, кроме пробельных\n",
    "\n",
    "__\\n__ – перенос строки\n",
    "\n",
    "__^__ – начало строки\n",
    "\n",
    "__$__ – конец строки\n",
    "\n",
    "__\\__ – экранирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Операторы:*__\n",
    "\n",
    "__?__ - предыдущий символ/группа может быть, а может не быть\n",
    "\n",
    "__+__ - предыдущий символ/группа может повторяться 1 и более раз\n",
    "\n",
    "__*__ - предыдущий символ/группа может повторяться 0 и более раз\n",
    "\n",
    "__{n,m}__ - предыдущий символ/группа может повторяться от от n до m включительно\n",
    "\n",
    "__{n,}__ - предыдущий символ/группа в скобках может повторяться n и более раз\n",
    "\n",
    "__{,m}__ - предыдущий символ/группа может повторяться до m раз\n",
    "\n",
    "__{n}__ - предыдущий символ/группа повторяется n раз\n",
    "\n",
    "Внутри групп не работают операторы __.__, __+__, __*__, их необходимо экранировать с помощью обратного слеша: \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall\n",
    "возвращает список всех найденных совпадений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос на внимательность: почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Кот сидит на столе'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая убирает url из строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
    "\n",
    "```\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
